{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMglz/3IUQapZFHmnQSTOzx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shreyas-ctrl/Certifications/blob/main/Medical_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eyKEtHiJnKZ",
        "outputId": "070f5c1b-6aef-4177-e6a9-b4450cf0e2ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.6/426.6 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.3/233.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.9/484.9 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires google-auth==2.43.0, but you have google-auth 2.45.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#Install Dependencies\n",
        "!pip install -qU google-generativeai==0.8.5 google-ai-generativelanguage==0.6.15 langgraph langchain langchain-google-genai openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import and secure API key input\n",
        "import os\n",
        "import getpass#Hide API keys\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage"
      ],
      "metadata": {
        "id": "gEO0ujn9LCpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Secure Gemini API Key Input\n",
        "os.environ[\"GOOGLE_API_KEY\"]=getpass.getpass(\"Enter your api key\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NWwmbukNlTX",
        "outputId": "27083386-f1d5-41ce-b72d-5ffe7890a9df"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your api key··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize Gemini 2.5 Flash\n",
        "llm=ChatGoogleGenerativeAI(model=\"models/gemini-2.5-flash\",temperature=0.2)"
      ],
      "metadata": {
        "id": "iOS2GJ2JOSJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Node to ask user for symptom\n",
        "def get_symptom(state: dict) -> dict:\n",
        "  symptom=input(\"Welcome to XYZ Hospital,Please enter your symptom\")\n",
        "  state[\"symptom\"]=symptom\n",
        "  return state\n"
      ],
      "metadata": {
        "id": "1zNUbb0URKy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Node to classify the symmptom\n",
        "def classify_symptom(state:dict)->dict:\n",
        "  prompt=(\n",
        "      \"you are a helpful medical assistant,classify the input into one of the categories\"\n",
        "      \"general,Emergency,mental health\"\n",
        "      f\"symptom : {state['symptom']}\"\n",
        "      'respond only with one word:general,emergency or mental'\n",
        "      \"#Example: input:I have fever,output :general\"\n",
        "  )\n",
        "\n",
        "  response=llm.invoke([HumanMessage(content=prompt)])\n",
        "  category=response.content.strip()\n",
        "  print(f\"LLM Classifies the symptom as:{category}\")\n",
        "  state[\"category\"]=category\n",
        "  return state"
      ],
      "metadata": {
        "id": "8YbQEjuzR_vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Router logic to route to correct node\n",
        "def symptom_router(state:dict)->dict:\n",
        "  cat=state[\"category\"].lower()\n",
        "  if \"general\" in cat:\n",
        "    return \"general\"\n",
        "  if \"emergency\" in cat:\n",
        "    return \"emergency\"\n",
        "  if \"mental\" in cat:\n",
        "    return \"mental\"\n",
        "  if \"general\" in cat:\n",
        "    return \"general\"\n"
      ],
      "metadata": {
        "id": "CWrjrD8LUvaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Category-specific response nodes\n",
        "def general_node(state: dict) -> dict:\n",
        "  state[\"answer\"] = f\" '{state['symptom']}' : seems general : directing you to general ward for consulting a doctor\"\n",
        "  return state\n",
        "\n",
        "def emergency_node(state:dict) -> dict:\n",
        "  state[\"answer\"] =f\" ' {state['symptom']}': It is a Medical Emergency : seeking immediate help\"\n",
        "  return state\n",
        "\n",
        "def mental_health_node(state: dict) -> dict:\n",
        "  state[\"answer\"] = f\" '{state['symptom']}: seems like a medical health issue: talk to our counsellor\"\n",
        "  return state"
      ],
      "metadata": {
        "id": "LKn5FDtQXrw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build a Langgraph\n",
        "builder = StateGraph(dict)\n",
        "\n",
        "#define the nodes\n",
        "builder.set_entry_point(\"get_symptom\")\n",
        "builder.add_node(\"get_symptom\", get_symptom)\n",
        "builder.add_node(\"classify\", classify_symptom)\n",
        "builder.add_node(\"general\", general_node)\n",
        "builder.add_node(\"emergency\", emergency_node)\n",
        "builder.add_node(\"mental_health\", mental_health_node)\n",
        "\n",
        "builder.add_edge(\"get_symptom\", \"classify\")\n",
        "builder.add_conditional_edges(\"classify\", symptom_router, {\n",
        "    \"general\": \"general\",\n",
        "    \"emergency\": \"emergency\",\n",
        "    \"mental_health\": \"mental_health\"\n",
        "})\n",
        "\n",
        "builder.add_edge(\"general\", END)\n",
        "builder.add_edge(\"emergency\", END)\n",
        "builder.add_edge(\"mental_health\", END)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Lv20dxfYSMT",
        "outputId": "a32d09b4-e29a-4609-a340-3d4b2ee099a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x7df9cee56690>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile and invoke the graph\n",
        "graph = builder.compile()\n",
        "final_state = graph.invoke({})\n",
        "print(\"final Output \\n\")\n",
        "print(final_state[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6weGsDYZBul",
        "outputId": "46ac433e-85e8-4689-abff-188b28dc51ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to XYZ Hospital,Please enter your symptomI have mild cough and cold along with headache and joint pain.\n",
            "LLM Classifies the symptom as:general\n",
            "final Output \n",
            "\n",
            " 'I have mild cough and cold along with headache and joint pain.' : seems general : directing you to general ward for consulting a doctor\n"
          ]
        }
      ]
    }
  ]
}